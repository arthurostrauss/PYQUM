{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:20:42.487287Z",
     "start_time": "2024-03-22T03:20:36.918063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-05 15:07:08,541 - qm - INFO     - Starting session: 3cfa08d0-ddae-4e4c-997e-3ae2077ed48a\n",
      "Absolute Path: /Users/adamachuck/Documents/GitHub/PYQUM/TEST/BETAsite/QM/OPXPlus/5-Flux-Tunable-Transmons/Standard Configuration\n",
      "QPU q1 control frequency: 3075363000 Hz\n",
      "QPU q2 control frequency: 3821889000 Hz\n",
      "QPU q3 control frequency: 3002163000 Hz\n",
      "QPU q4 control frequency: 3591519000 Hz\n",
      "QPU q5 control frequency: 4468564000 Hz\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cross entropy benchmarking of two qubits (XEB) is a method for characterizing the fidelity of a two-qubit gate.\n",
    "The XEB sequence consists of a random sequence of single-qubit gates and a two-qubit gate, followed by a measurement.\n",
    "The sequence is repeated many times, and the results are used to calculate the cross entropy between the ideal and measured states.\n",
    "The cross entropy is a measure of the distance between two probability distributions, and is related to the fidelity of the two-qubit gate.\n",
    "The cross entropy is calculated as follows:\n",
    "    1. The ideal state is calculated by applying the sequence of single-qubit gates and the two-qubit gate to the initial state |00>.\n",
    "    2. The measured state is calculated by applying the sequence of single-qubit gates to the initial state |00>, followed by a measurement.\n",
    "    3. The cross entropy is calculated between the ideal and measured states.\n",
    "The cross entropy is calculated for a range of sequence depths, and the results are used to calculate the fidelity of the two-qubit gate.\n",
    "In this script, we provide an example of how to run an XEB sequence on the OPX.\n",
    "\n",
    "Author: Arthur Strauss - Quantum Machines\n",
    "Created: 16/01/2024 (Last modified: 16/01/2024)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from qm import QuantumMachinesManager\n",
    "from qm.qua import *\n",
    "from qm.simulate.credentials import create_credentials\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/adamachuck/Documents/GitHub/PYQUM/TEST/BETAsite/QM/OPXPlus/Configurations')\n",
    "# sys.path.append('/Users/arthurostrauss/Library/CloudStorage/OneDrive-QMMachinesLTD/GitHub/PYQUM/TEST/BETAsite/QM/OPXPlus/Configurations')\n",
    "from configuration import *\n",
    "from qm.simulate import SimulationConfig\n",
    "from matplotlib import pyplot as plt\n",
    "import pprint\n",
    "from macros import multiplexed_readout, qua_declaration, cz_gate\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import CZGate, RXGate, RYGate, RZGate, HGate, UnitaryGate, TGate, XGate, YGate, CPhaseGate\n",
    "from qiskit.quantum_info import Statevector\n",
    "from time import sleep\n",
    "from scipy.linalg import sqrtm\n",
    "import warnings\n",
    "\n",
    "import os, fnmatch\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:20:50.838942Z",
     "start_time": "2024-03-22T03:20:50.830414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated runtime: 73.94594594594595 minutes\n",
      "real-time: 6.20697168 minutes\n"
     ]
    }
   ],
   "source": [
    "qubits = [4,5] # |00> = |q5,q4> |q4=0> = 10 + 00\n",
    "apply_cz = False\n",
    "seqs = 57  # 101 # Number of random sequences to run per depth\n",
    "max_depth = 180  # 7  # Max depth of the XEB sequence\n",
    "step = 2  # Step for the depth iteration\n",
    "avgs = 280  # 101  # Number of averages per sequence\n",
    "depths = np.arange(1, max_depth+1, step)  # Create an array of depths to iterate through\n",
    "gate_set_choice = 2  # Choose the gate-set: 1, 2, 3 or 4\n",
    "impose_0_cycle = True\n",
    "\n",
    "time_per_point = 16/(420*20*37) # in min\n",
    "print(f\"Estimated runtime: {seqs*avgs*len(depths)*time_per_point} minutes\")\n",
    "real_time = seqs*avgs*len(depths)*thermalization_time + seqs*avgs*(depths[0]+depths[-1])*(len(depths)//2)*pi_len\n",
    "print(\"real-time: %s minutes\"%(real_time*1e-9/60))\n",
    "\n",
    "save_notebook_dir = save_dir.parents[6]/\"data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting & Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:21:05.233358Z",
     "start_time": "2024-03-22T03:21:05.229127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data with keyword '':\n",
      "\n",
      "0. XEB_q4_s(81)_d(180)_g(2)_cz(0)_0cyc(1).npz\n",
      "1. XEB_q4_s(57)_d(180)_g(2)_cz(0)_0cyc(1).npz\n",
      "2. XEB_q4_5_s(57)_d(180)_g(2)_cz(0)_0cyc(1).npz\n",
      "3. XEB_q4_5_s(79)_d(270)_g(2)_cz(0)_0cyc(1).npz\n",
      "4. XEB_q4_5_s(81)_d(180)_g(2)_cz(0)_0cyc(1).npz\n",
      "5. XEB_q5_s(81)_d(180)_g(2)_cz(0)_0cyc(1).npz\n",
      "6. XEB_q4_5_s(57)_d(18)_g(2)_cz(0)_0cyc(1).npz\n",
      "7. XEB_q4_5_s(142)_d(20)_g(2)_cz(1)_0cyc(1).npz\n",
      "8. XEB_q5_s(57)_d(180)_g(2)_cz(0)_0cyc(1).npz\n",
      "9. XEB_q4_s(81)_d(240)_g(2)_cz(0)_0cyc(1).npz\n",
      "10. XEB_q5_s(81)_d(480)_g(2)_cz(0)_0cyc(1).npz\n",
      "11. XEB_q4_5_s(79)_d(27)_g(2)_cz(0)_0cyc(1).npz\n",
      "12. XEB_q2_s(81)_d(240)_g(2)_cz(0)_0cyc(1).npz\n"
     ]
    }
   ],
   "source": [
    "flist = fnmatch.filter(os.listdir(save_notebook_dir), 'XEB*')\n",
    "keyword = \"\"\n",
    "flist = list(filter(lambda x: keyword in x, flist))\n",
    "print(\"Saved data with keyword '%s':\\n\" %keyword)\n",
    "for i, f in enumerate(flist): print(\"%s. %s\" %(i,f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:28:09.279364Z",
     "start_time": "2024-03-22T03:28:09.268863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading selected data:\n",
    "filename = flist[1]\n",
    "npz_file = np.load(save_notebook_dir/f\"{filename}\", allow_pickle=True)\n",
    "\n",
    "# Create an empty dictionary to store variables\n",
    "variables = {}\n",
    "\n",
    "# Iterate through keys and store variables in the dictionary\n",
    "for key in npz_file.files: variables[key] = npz_file[key]\n",
    "\n",
    "# Close the npz file after loading the data\n",
    "npz_file.close()\n",
    "\n",
    "# loading variables from file:\n",
    "g = variables['g']\n",
    "a = variables['a']\n",
    "quadratures = variables['quadratures']\n",
    "state = variables['state'].item()\n",
    "# counts = variables['counts'][()]\n",
    "counts = variables['counts'].item()\n",
    "gate_set_choice = variables['gate_set_choice']\n",
    "seqs = variables['seqs']\n",
    "max_depth = variables['max_depth']\n",
    "step = variables['step']\n",
    "depths = np.arange(1, max_depth+1, step)\n",
    "avgs = variables['avgs']\n",
    "qubits = variables['qubits']\n",
    "apply_cz = variables['apply_cz']\n",
    "impose_0_cycle = variables['impose_0_cycle']\n",
    "\n",
    "print(\"qubits = %s\" %qubits)\n",
    "print(\"seqs = %s\" %seqs)\n",
    "print(\"max_depth = %s\" %max_depth)\n",
    "print(\"step = %s\" %step)\n",
    "print(\"avgs = %s\" %avgs)\n",
    "print(\"apply_cz = %s\" %apply_cz)\n",
    "print(\"impose_0_cycle = %s\" %impose_0_cycle)\n",
    "print(\"gate_set_choice = %s\" %gate_set_choice)\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivations from set / loaded parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:22:32.919497Z",
     "start_time": "2024-03-22T03:22:32.907331Z"
    }
   },
   "outputs": [],
   "source": [
    "# For QUA & Simulation:\n",
    "qubits = list(qubits)\n",
    "qubits_el = [f\"q{i}_xy\" for i in qubits]\n",
    "n_qubits = len(qubits)\n",
    "dim = 2 ** n_qubits\n",
    "multiplexed = qubits + [x+1 for x in range(5) if (x+1) not in qubits]\n",
    "print(f\"multiplexed: {multiplexed}\")\n",
    "\n",
    "cz_type = \"const_wf\"\n",
    "if n_qubits < 2:\n",
    "    apply_cz = False\n",
    "    print(\"CZ gate not applied (less than 2 qubits)\")\n",
    "    disjoint_counts = False\n",
    "\n",
    "# For Data Saving:\n",
    "qubits_involved = '_'.join([str(x) for x in qubits])\n",
    "comment = f\"s({seqs})_d({max_depth})_g({gate_set_choice})_cz({int(apply_cz)})_0cyc({int(impose_0_cycle)})\"\n",
    "filename = f\"XEB_q{qubits_involved}_{comment}\"\n",
    "\n",
    "print(f\"qubits involved: {qubits_involved}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Unitary & Amplitude Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:22:33.971795Z",
     "start_time": "2024-03-22T03:22:33.963883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random gates\n",
    "X90, Y90, Z180 = RXGate(np.pi / 2), RYGate(np.pi / 2), RZGate(np.pi)\n",
    "Z45 = RZGate(1 * np.pi / 4)\n",
    "T, X, Y, H = TGate(), XGate(), YGate(), HGate()\n",
    "W = UnitaryGate((X.to_matrix() + Y.to_matrix())/np.sqrt(2), label='W')\n",
    "# SW = UnitaryGate(sqrtm(W), label='SW')\n",
    "SW = UnitaryGate(np.array([[1, -np.sqrt(1j)], [np.sqrt(-1j), 1]])/np.sqrt(2), label='SW') # from Supremacy paper\n",
    "\n",
    "XY90 = UnitaryGate((X90.to_matrix() + Y90.to_matrix()) / np.sqrt(3), label=\"XY90\")\n",
    "# XY90 = UnitaryGate((T.to_matrix() @ X90.to_matrix()), label=\"XY90\")\n",
    "# XY90 = UnitaryGate((X90.to_matrix() @ T.to_matrix()), label=\"XY90\")\n",
    "\n",
    "XY90mm = UnitaryGate((-X90.to_matrix() - Y90.to_matrix()) / np.sqrt(3), label=\"XY90mm\")\n",
    "XY90pm = UnitaryGate((X90.to_matrix() - Y90.to_matrix()), label=\"XY90pm\")\n",
    "XY90mp = UnitaryGate((-X90.to_matrix() + Y90.to_matrix()), label=\"XY90mp\")\n",
    "CZ, CP = CZGate(), CPhaseGate(np.pi/2)\n",
    "\n",
    "X90_dict = {\"gate\": X90, 'amp_matrix': np.array([1., 0., 0., 1.])}\n",
    "# Y90_dict = {\"gate\": Y90, 'amp_matrix': np.array([0., 1., -1., 0.])}\n",
    "Y90_dict = {\"gate\": Y90, 'amp_matrix': np.array([0., -1., 1., 0.])} # verified w/ CX\n",
    "# XY90_dict = {\"gate\": XY90, 'amp_matrix': 0.70710678 * np.array([1., 1., -1., 1.])}\n",
    "XY90_dict = {\"gate\": XY90, 'amp_matrix': 0.70710678 * np.array([1., -1., 1., 1.])} # verified w/ CX\n",
    "\n",
    "# TODO: For the dicts below, need to check the validity of amplitude matrices!\n",
    "XY90mm_dict = {\"gate\": XY90mm, 'amp_matrix': 0.70710678 * np.array([-1., -1., 1., -1.])}\n",
    "XY90pm_dict = {\"gate\": XY90pm, 'amp_matrix': 0.70710678 * np.array([1., -1., 1., 1.])}\n",
    "XY90mp_dict = {\"gate\": XY90mp, 'amp_matrix': 0.70710678 * np.array([-1., 1., -1., 1.])}\n",
    "T_dict = {\"gate\": T, 'amp_matrix': np.array([1., 0., 0., 1])}  # No actual need for amp_matrix,\n",
    "# but here for consistency with the current workflow\n",
    "SW_dict = {\"gate\": SW, 'amp_matrix': 0.70710678 * np.array([1., -1., 1., 1.])}  # Amp matrix similar to XY90 # verified w/ CX\n",
    "\n",
    "# Possible gate sets\n",
    "gate_dict1 = {0: X90_dict, 1: Y90_dict, 2: T_dict}  # https://arxiv.org/abs/1608.00263\n",
    "gate_dict2 = {0: X90_dict, 1: Y90_dict, 2: SW_dict}  # Supremacy gate set (https://www.nature.com/articles/s41586-019-1666-5)\n",
    "gate_dict3 = {0: X90_dict, 1: Y90_dict, 2: XY90_dict, 3: XY90mm_dict, 4: XY90pm_dict, 5: XY90mp_dict}  # https://arxiv.org/abs/2001.08343\n",
    "gate_dict4 = {0: X90_dict, 1: Y90_dict, 2: XY90_dict}  # Currently used in the QM XEB example (XY90==XY90pp)\n",
    "gate_sets = [gate_dict1, gate_dict2, gate_dict3, gate_dict4]\n",
    "\n",
    "# Gate set choice:\n",
    "gate_dict = gate_sets[gate_set_choice - 1]\n",
    "random_gates = len(gate_dict)\n",
    "print(\"gate_dict: %s\" %gate_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:22:35.743622Z",
     "start_time": "2024-03-22T03:22:35.741321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check Unitary:\n",
    "from qiskit.quantum_info import Operator\n",
    "\n",
    "Operator(XY90).is_unitary()\n",
    "print(\"Check Identity: \")\n",
    "print(XY90.to_matrix()@XY90.to_matrix().conjugate().transpose())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running QUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmm = QuantumMachinesManager(host=qop_ip, port=qop_port, cluster_name=cluster_name, octave=octave_config)\n",
    "# qmm = QuantumMachinesManager(host=\"tyler-263ed49e.dev.quantum-machines.co\", port=443, credentials=create_credentials())\n",
    "# qubits = [\"q0\", \"q1\"]  # Fix which qubits to use on the chip (quantum elements in the configuration)\n",
    "# readout_elements = [\"rr0\", \"rr1\"]  # Fix which readout resonators to use on the chip (readout elements in the\n",
    "# configuration)\n",
    "# ge_threshold = 0.1  # Threshold for the ground state population (used for the readout)\n",
    "# thermalization_time = 100  # Thermalization time for the qubits (in ns)\n",
    "simulate = False\n",
    "\n",
    "def assign_amplitude_matrix(gate, a):\n",
    "    \"\"\"\n",
    "    QUA Macro for assigning the amplitude matrix arguments for a given gate index.\n",
    "    :param gate: Gate index\n",
    "    :param a: Amplitude matrix arguments\n",
    "    \"\"\"\n",
    "    with switch_(gate):\n",
    "        for i in range(random_gates):\n",
    "            with case_(i):\n",
    "                for j in range(4):\n",
    "                    assign(a[j], gate_dict[i]['amp_matrix'][j])\n",
    "\n",
    "\n",
    "# QUA Program\n",
    "\n",
    "with program() as xeb:\n",
    "    # Declare QUA variables\n",
    "    I, I_st, Q, Q_st, n, n_st = qua_declaration(nb_of_qubits=len(multiplexed))\n",
    "    # I, Q = [declare(fixed) for _ in range(2)], [declare(fixed) for _ in range(2)]\n",
    "    s, tot_state_ = declare(int), declare(int)\n",
    "    d, d_ = declare(int), declare(int)\n",
    "    g = [declare(int, size=max_depth) for _ in range(n_qubits)]  # Gate indices list for both qubits\n",
    "    a = [[declare(fixed, size=max_depth) for _ in range(4)] for _ in\n",
    "         range(n_qubits)]  # Amplitude matrices for both qubits (for all depths)\n",
    "    counts = [declare(int, value=0) for _ in range(dim)] # Counts for the 4 possible states\n",
    "    state = [declare(bool) for _ in range(len(multiplexed))] # State of the qubits\n",
    "    # Declare streams\n",
    "    # I_st, Q_st = [declare_stream() for _ in range(2)], [declare_stream() for _ in range(2)]\n",
    "    s_st = declare_stream()\n",
    "    counts_st = [declare_stream() for _ in range(dim)]\n",
    "    state_st = [declare_stream() for _ in range(len(multiplexed))]\n",
    "    g_st = [declare_stream() for _ in range(n_qubits)]\n",
    "\n",
    "    # Randomize the random number generator\n",
    "    r = Random()\n",
    "    r.set_seed(12321)\n",
    "    # r.set_seed(11111)\n",
    "\n",
    "    # If we are simulating, we need to update the frequency of the qubits to 0 to visualize the sequence\n",
    "    # if simulate:\n",
    "    if True:\n",
    "        a_st = [[declare_stream() for _ in range(4)] for _ in range(n_qubits)]\n",
    "        # for qubit in qubits_el:\n",
    "            # update_frequency(qubit, 0)\n",
    "\n",
    "    # Generate and run the XEB sequences\n",
    "    with for_(s, 0, s < seqs, s + 1):\n",
    "        with for_each_(d, depths): # max-depths\n",
    "            # Randomize the sequence of single-qubit gates\n",
    "            # NOTE: different from Google: randomizing for each growing-depths and sequences\n",
    "            with for_(d_, 0, d_ < d, d_ + 1):\n",
    "                for q in range(n_qubits):\n",
    "                    with if_(d_ == 0):\n",
    "                        if impose_0_cycle: assign(g[q][d_], r.rand_int(random_gates-1)) # to ensure 0-cycle isn't repeated on the 1-cycle\n",
    "                        else: assign(g[q][d_], r.rand_int(random_gates))\n",
    "                    with if_(d_ > 0):\n",
    "                        assign(g[q][d_], r.rand_int(random_gates))\n",
    "                        with while_(g[q][d_] == g[q][d_ - 1]):  # Make sure the same gate is not applied twice in a row\n",
    "                            assign(g[q][d_], r.rand_int(random_gates))\n",
    "                    # Map the sequence indices into amplitude matrix arguments (each index corresponds to a random gate)\n",
    "                    assign_amplitude_matrix(g[q][d_], [a[q][i][d_] for i in range(4)])\n",
    "                    save(g[q][d_], g_st[q])\n",
    "\n",
    "                    # if simulate:\n",
    "                    if True:\n",
    "                        for amp_matrix_element in range(4):\n",
    "                            save(a[q][amp_matrix_element][d_], a_st[q][amp_matrix_element])\n",
    "\n",
    "            # Run the XEB sequence\n",
    "            with for_(n, 0, n < avgs, n + 1):\n",
    "                # save(n, n_st)\n",
    "                # Reset the qubits to their ground states (here simple wait but could be an active reset macro)\n",
    "                if simulate:\n",
    "                    wait(25, *qubits_el)\n",
    "                else:\n",
    "                    wait(3 * thermalization_time, *qubits_el)\n",
    "\n",
    "                # NOTE: imposing first gate at 0-cycle:\n",
    "                if impose_0_cycle:\n",
    "                    for q in range(n_qubits): \n",
    "                        play(\"x90\" * amp(*SW_dict[\"amp_matrix\"]), qubits_el[q])\n",
    "                        # play(\"y90\", qubits_el[q])\n",
    "                        # play(\"x180\", qubits_el[q])\n",
    "\n",
    "                # Play all cycles generated for sequence s of depth d\n",
    "                with for_(d_, 0, d_ < d, d_ + 1):\n",
    "                    for q in range(n_qubits):  # Play single qubit gates on both qubits\n",
    "                        if T_dict in gate_dict.values():\n",
    "                            with switch_(g[q][d_], unsafe=True):\n",
    "                                for j in range(2):\n",
    "                                    with case_(j):\n",
    "                                        play(\"x90\" * amp(*[a[q][i][d_] for i in range(4)]), qubits_el[q])\n",
    "                                with case_(2):\n",
    "                                    frame_rotation(np.pi/4, qubits_el[q])\n",
    "                        elif SW_dict in gate_dict.values():\n",
    "                            # raise NotImplementedError(\"SW gate not readily implemented yet\")\n",
    "                            # warnings.warn(\"SW gate not readily implemented yet\")\n",
    "                            play(\"x90\" * amp(*[a[q][i][d_] for i in range(4)]), qubits_el[q])\n",
    "                        else:\n",
    "                            play(\"x90\" * amp(*[a[q][i][d_] for i in range(4)]), qubits_el[q])\n",
    "                    align()\n",
    "                    if apply_cz:\n",
    "                        # Insert your two-qubit gate macro here\n",
    "                        cz_gate(qubits[0], qubits[1], cz_type)\n",
    "                        frame_rotation_2pi(eval(f\"cz{5}_{4}_2pi_dev\"), \"q5_xy\")\n",
    "                        frame_rotation_2pi(eval(f\"cz{4}_{5}_2pi_dev\"), \"q4_xy\")\n",
    "                    align()\n",
    "\n",
    "                # Measure the state (insert your readout macro here)\n",
    "                multiplexed_readout(I, I_st, Q, Q_st, resonators=multiplexed, weights=\"rotated_\")\n",
    "\n",
    "                # State discrimination\n",
    "                for q in range(n_qubits):\n",
    "                    assign(state[q], I[q] > eval(f\"ge_threshold_q{multiplexed[q]}\"))\n",
    "                    save(state[q], state_st[q])\n",
    "                    assign(tot_state_, tot_state_ + 2**q * Cast.to_int(state[q]))\n",
    "                    \n",
    "\n",
    "                # assign(tot_state_, Cast.to_int(state[0]) + 2 * Cast.to_int(state[1]))\n",
    "                # assign(tot_state_, Cast.to_int(state[1]) + 2 * Cast.to_int(state[0]))\n",
    "                with switch_(tot_state_):\n",
    "                    for i in range(dim):  # Bitstring conversion\n",
    "                        with case_(i):\n",
    "                            assign(counts[i], counts[i] + 1)  # counts for 00, 01, 10 and 11\n",
    "                assign(tot_state_, 0)\n",
    "            for i in range(dim):  # Resetting Bitstring collection\n",
    "                save(counts[i], counts_st[i])\n",
    "                assign(counts[i], 0)\n",
    "\n",
    "            # Save the sequence iteration to get the progress bar\n",
    "            save(s, s_st)\n",
    "\n",
    "    # Save the results\n",
    "    with stream_processing():\n",
    "        s_st.save(\"s\")\n",
    "        for q in range(n_qubits):\n",
    "            g_st[q].save_all(f\"g{q}\")\n",
    "            I_st[q].buffer(avgs).map(FUNCTIONS.average()).buffer(len(depths)).save_all(f\"I{q}\")\n",
    "            Q_st[q].buffer(avgs).map(FUNCTIONS.average()).buffer(len(depths)).save_all(f\"Q{q}\")\n",
    "            state_st[q].boolean_to_int().buffer(avgs).map(FUNCTIONS.average()).buffer(len(depths)).save_all(\n",
    "                f\"state{q}\")\n",
    "        for i in range(dim):\n",
    "            string = \"s\" + bin(i)[2:].zfill(n_qubits)\n",
    "            counts_st[i].buffer(len(depths)).save_all(string)\n",
    "\n",
    "        # if simulate:\n",
    "        if True:\n",
    "            for q in range(n_qubits):\n",
    "                for d_ in range(4):\n",
    "                    a_st[q][d_].save_all(f\"a{q + 1}_{bin(d_)[2:].zfill(2)}\")\n",
    "\n",
    "if simulate:\n",
    "    job = qmm.simulate(config, xeb, SimulationConfig(15000))\n",
    "    job.get_simulated_samples().con1.plot()\n",
    "    job.get_simulated_samples().con2.plot()\n",
    "    plt.show()\n",
    "else:\n",
    "    qm = qmm.open_qm(config)\n",
    "    job = qm.execute(xeb)\n",
    "\n",
    "job.result_handles.wait_for_all_values()\n",
    "result = job.result_handles\n",
    "g = [result.get(f\"g{i}\").fetch_all()['value'] for i in range(n_qubits)]\n",
    "\n",
    "if simulate:\n",
    "    a = {f\"a{q + 1}_{bin(i)[2:].zfill(2)}\": result.get(f\"a{q + 1}_{bin(i)[2:].zfill(2)}\").fetch_all()['value'] for q in\n",
    "         range(n_qubits) for i in range(4)}\n",
    "else:\n",
    "    a = {f\"a{q + 1}_{bin(i)[2:].zfill(2)}\": result.get(f\"a{q + 1}_{bin(i)[2:].zfill(2)}\").fetch_all()['value'] for q in\n",
    "     range(n_qubits) for i in range(4)}\n",
    "    quadratures = {f\"I{i}\": result.get(f\"I{i}\").fetch_all()['value'] for i in range(n_qubits)}\n",
    "    quadratures.update({f\"Q{i}\": result.get(f\"Q{i}\").fetch_all()['value'] for i in range(n_qubits)})\n",
    "    \n",
    "    state = {f\"state{i}\": result.get(f\"state{i}\").fetch_all()['value'] for i in range(n_qubits)}\n",
    "    counts = {bin(i)[2:].zfill(n_qubits): result.get(f\"s{bin(i)[2:].zfill(n_qubits)}\").fetch_all()['value'] for i in range(dim)}\n",
    "    # state1, state2 = [result.get(f'state{i}').fetch_all()['value'] for i in [1, 2]]\n",
    "    # state00, state01, state10, state11 = [result.get(f's{bin(i)[2:].zfill(2)}').fetch_all()['value'] for\n",
    "    #                                       i in\n",
    "    #                                       range(4)]\n",
    "    # \n",
    "    # print(f\"state1:\\n {state1}, state2:\\n {state2}\")\n",
    "    # print(f\"state00:\\n {state00}, state01:\\n {state01}, state10:\\n {state10}, state11:\\n {state11}\")\n",
    "\n",
    "\n",
    "    # Close the quantum machines at the end in order to put all flux biases to 0 so that the fridge doesn't heat-up\n",
    "    qm.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data saving:\n",
    "np.savez(save_notebook_dir/filename, g=g, a=a, quadratures=quadratures, state=state, counts=counts, \n",
    "            gate_set_choice=gate_set_choice, seqs=seqs, max_depth=max_depth, step=step, avgs=avgs, qubits=qubits,\n",
    "            apply_cz=apply_cz, impose_0_cycle=impose_0_cycle)\n",
    "print(\"Data saved as %s.npz\" %filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:40:46.902236Z",
     "start_time": "2024-03-22T03:40:46.170509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rebuild gate sequences generated from the QUA:\n",
    "print(\"n_qubits: %s\" %n_qubits)\n",
    "\n",
    "disjoint_counts = True\n",
    "# assert (apply_cz and not disjoint_counts) or (not apply_cz and disjoint_counts), \"Invalid configuration, cannot have disjoint counts if cz enabled\" \n",
    "\n",
    "sq_indices = []\n",
    "idx = 0\n",
    "for s in range(seqs):\n",
    "    sq_indices.append([])\n",
    "    for i, d in enumerate(depths):\n",
    "        sq_indices[s].append(np.zeros((n_qubits, d), dtype=int))\n",
    "        for d_ in range(d):\n",
    "            for q in range(n_qubits):\n",
    "                sq_indices[s][i][q][d_] = g[q][idx]\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "def cross_entropy(p, q, epsilon=1e-15):\n",
    "    \"\"\"\n",
    "    Calculate cross entropy between two probability distributions.\n",
    "\n",
    "    Parameters:\n",
    "    - p: numpy array, the true probability distribution\n",
    "    - q: numpy array, the predicted probability distribution\n",
    "    - epsilon: small value to avoid taking the logarithm of zero\n",
    "\n",
    "    Returns:\n",
    "    - Cross entropy between p and q\n",
    "    \"\"\"\n",
    "    q = np.maximum(q, epsilon)  # Avoid taking the logarithm of zero\n",
    "\n",
    "    # print(f\"p: {p}, \\nq: {q}\")\n",
    "\n",
    "    x_entropy = -np.sum(p * np.log(q))\n",
    "\n",
    "    return x_entropy\n",
    "\n",
    "if not disjoint_counts:\n",
    "    records = []\n",
    "    incoherent_distribution = np.ones(dim) / (dim)\n",
    "    expected_probs = np.zeros((seqs, len(depths), dim))\n",
    "    measured_probs = np.zeros((seqs, len(depths), dim))\n",
    "    fidelities = np.zeros((seqs, len(depths)))\n",
    "    singularity = []\n",
    "    outlier = []\n",
    "else:\n",
    "    records = [[], []]\n",
    "    incoherent_distribution = np.ones(2)/2\n",
    "    expected_probs = np.zeros((n_qubits, seqs, len(depths), 2))\n",
    "    measured_probs = np.zeros((n_qubits, seqs, len(depths), 2))\n",
    "    fidelities = np.zeros((n_qubits, seqs, len(depths)))\n",
    "    singularity = [[], []]\n",
    "    outlier = [[], []]\n",
    "\n",
    "# Reconstruct every Circuit from the previously rebuilt gate sequences: (using Qiskit)\n",
    "circuits_list = []\n",
    "\n",
    "for s in range(seqs):\n",
    "    circuits_list.append([])\n",
    "    for d_, d in enumerate(depths):\n",
    "        qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "        # NOTE: imposing first gate at 0-cycle:\n",
    "        gate_cycle_0 = SW # XY90, H\n",
    "        if impose_0_cycle:\n",
    "            for q in range(n_qubits):\n",
    "                qc.append(gate_cycle_0, [q]) \n",
    "                # qc.append(gate_cycle_0, [1])\n",
    "\n",
    "        for k in range(d):\n",
    "            sq_gates = [gate_dict[sq_indices[s][d_][q][k]][\"gate\"] for q in range(n_qubits)]\n",
    "            for q in range(n_qubits):\n",
    "                qc.append(sq_gates[q], [q])\n",
    "\n",
    "            if apply_cz: \n",
    "                qc.append(CZ, [0, 1])\n",
    "\n",
    "        circuits_list[s].append(qc)\n",
    "        if not disjoint_counts:\n",
    "            expected_probs[s, d_] = np.round(Statevector(qc).probabilities(), 5) # [1, 0]\n",
    "            measured_probs[s, d_] = np.array([counts[bin(i)[2:].zfill(n_qubits)][s][d_] for i in range(dim)]) / avgs\n",
    "    \n",
    "            xe_incoherent = cross_entropy(incoherent_distribution, expected_probs[s, d_])\n",
    "            xe_measured = cross_entropy(measured_probs[s, d_], expected_probs[s, d_])\n",
    "            xe_expected = cross_entropy(expected_probs[s, d_], expected_probs[s, d_])\n",
    "    \n",
    "            f_xeb = ((xe_incoherent - xe_measured) / (xe_incoherent - xe_expected))\n",
    "            if np.isinf(f_xeb) or np.isnan(f_xeb):\n",
    "                print(f\"seq {s + 1}, depth {depths[d_]}: f_xeb = {f_xeb}\")\n",
    "                print(f\"<<xe>>: xe_incoherent: {xe_incoherent}, xe_measured: {xe_measured}, xe_expected: {xe_expected}\")\n",
    "                singularity.append((s, d_))\n",
    "                fidelities[s, d_] = np.nan  # Set all singularities to NaN\n",
    "            elif f_xeb < 0 or f_xeb > 1:\n",
    "                print(f\"seq {s + 1}, depth {depths[d_]}: f_xeb = {f_xeb}\")\n",
    "                print(f\"<<xe>>: xe_incoherent: {xe_incoherent}, xe_measured: {xe_measured}, xe_expected: {xe_expected}\")\n",
    "                outlier.append((s, d_))\n",
    "                fidelities[s, d_] = np.nan  # Set all outliers to NaN\n",
    "            else:\n",
    "                fidelities[s, d_] = f_xeb\n",
    "                pass\n",
    "                # print(f\"seq {s + 1}, depth {depths[d_]}: f_xeb = {f_xeb}\")\n",
    "                # print(f\"<<xe>>: xe_incoherent: {xe_incoherent}, xe_measured: {xe_measured}, xe_expected: {xe_expected}\")        \n",
    "            \n",
    "                records += [\n",
    "                {\n",
    "                    \"sequence\": s,\n",
    "                    \"depth\": depths[d_],\n",
    "                    \"pure_probs\": expected_probs[s, d_],\n",
    "                    \"sampled_probs\": measured_probs[s, d_],\n",
    "                    \"circuit\": circuits_list[s][d_],\n",
    "                }\n",
    "            ]\n",
    "        else:\n",
    "            for i in range(n_qubits):\n",
    "                expected_probs[i][s, d_] = np.round(Statevector(qc).probabilities([i]), 5) # [1, 0]\n",
    "                print(f\"expected_probs[{i}][{s}, {d_}]: {expected_probs[i][s, d_]}\")\n",
    "                measured_probs[i][s, d_] = np.array([1-state[f\"state{i}\"][s][d_], state[f\"state{i}\"][s][d_]]) \n",
    "                print(f\"measured_probs[{i}][{s}, {d_}]: {measured_probs[i][s, d_]}\")\n",
    "        \n",
    "                xe_incoherent = cross_entropy(incoherent_distribution, expected_probs[i][s, d_])\n",
    "                xe_measured = cross_entropy(measured_probs[i][s, d_], expected_probs[i][s, d_])\n",
    "                xe_expected = cross_entropy(expected_probs[i][s, d_], expected_probs[i][s, d_])\n",
    "        \n",
    "                f_xeb = ((xe_incoherent - xe_measured) / (xe_incoherent - xe_expected))\n",
    "                if np.isinf(f_xeb) or np.isnan(f_xeb):\n",
    "                    print(f\"seq {s + 1}, depth {depths[d_]}: f_xeb = {f_xeb}\")\n",
    "                    print(f\"<<xe>>: xe_incoherent: {xe_incoherent}, xe_measured: {xe_measured}, xe_expected: {xe_expected}\")\n",
    "                    singularity[i].append((s, d_))\n",
    "                    fidelities[i][s, d_] = np.nan  # Set all singularities to NaN\n",
    "                elif f_xeb < 0 or f_xeb > 1:\n",
    "                    print(f\"seq {s + 1}, depth {depths[d_]}: f_xeb = {f_xeb}\")\n",
    "                    print(f\"<<xe>>: xe_incoherent: {xe_incoherent}, xe_measured: {xe_measured}, xe_expected: {xe_expected}\")\n",
    "                    outlier[i].append((s, d_))\n",
    "                    fidelities[i][s, d_] = np.nan  # Set all outliers to NaN\n",
    "                else:\n",
    "                    fidelities[i][s, d_] = f_xeb\n",
    "                    pass\n",
    "                    # print(f\"seq {s + 1}, depth {depths[d_]}: f_xeb = {f_xeb}\")\n",
    "                    # print(f\"<<xe>>: xe_incoherent: {xe_incoherent}, xe_measured: {xe_measured}, xe_expected: {xe_expected}\")        \n",
    "                \n",
    "                    records[i] += [\n",
    "                    {\n",
    "                        \"sequence\": s,\n",
    "                        \"depth\": depths[d_],\n",
    "                        \"pure_probs\": expected_probs[i][s, d_],\n",
    "                        \"sampled_probs\": measured_probs[i][s, d_],\n",
    "                        \"circuit\": circuits_list[s][d_],\n",
    "                    }\n",
    "                ]\n",
    "        \n",
    "print(f\"singularities: {singularity}\")\n",
    "print(f\"overall singularities: {len(singularity)/seqs/len(depths)*100}%\")\n",
    "print(f\"outliers: {outlier}\")\n",
    "print(f\"overall outliers: {len(outlier)/seqs/len(depths)*100}%\")\n",
    "\n",
    "if not disjoint_counts:\n",
    "    for record in records:\n",
    "        e_u = np.sum(record[\"pure_probs\"] ** 2)\n",
    "        u_u = np.sum(record[\"pure_probs\"]) / dim\n",
    "        m_u = np.sum(record[\"pure_probs\"] * record[\"sampled_probs\"])\n",
    "        record.update(e_u=e_u, u_u=u_u, m_u=m_u)\n",
    "else:\n",
    "    for i in range(n_qubits):\n",
    "        for record in records[i]:\n",
    "            e_u = np.sum(record[\"pure_probs\"] ** 2)\n",
    "            u_u = np.sum(record[\"pure_probs\"]) / 2\n",
    "            m_u = np.sum(record[\"pure_probs\"] * record[\"sampled_probs\"])\n",
    "            record.update(e_u=e_u, u_u=u_u, m_u=m_u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Singularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:44:18.666964Z",
     "start_time": "2024-03-22T03:44:18.631987Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Draw the circuit of your choice: first index is the sequence, second index is the depth index in depths array\n",
    "if not disjoint_counts:\n",
    "    for s, d_ in singularity:\n",
    "        print(s, d_)\n",
    "        print(circuits_list[s][d_])\n",
    "    # circuits_list[223][1].draw(\"mpl\", style=\"clifford\")\n",
    "else:\n",
    "    for i in range(n_qubits):\n",
    "        for s, d_ in singularity[i]:\n",
    "            print(s, d_)\n",
    "            print(circuits_list[s][d_])\n",
    "        # circuits_list[223][1].draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, d_ in singularity:\n",
    "    print(expected_probs[s, d_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Gate Sequences history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:44:31.953088Z",
     "start_time": "2024-03-22T03:44:31.605144Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_amp_matrix = 0\n",
    "idx = 0\n",
    "print(\"seqs: %s, depths: %s\" %(seqs, depths))\n",
    "for s in range(seqs):\n",
    "    for id, d in enumerate(depths):\n",
    "        print(\"circuit of seqs-%s, depths-%s:\\n %s\" %(s+1, d, circuits_list[s][id]))\n",
    "        if check_amp_matrix:\n",
    "            for d_ in range(d):\n",
    "                print(f\"cycle-{d_+1}\")\n",
    "                for q in range(n_qubits):\n",
    "                    print(f'a{q+1}:\\n')\n",
    "                    print([a[f\"a{q+1}_{bin(i)[2:].zfill(2)}\"][idx] for i in range(4)])\n",
    "                idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Speckles from counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:44:44.224274Z",
     "start_time": "2024-03-22T03:44:41.153915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "def create_subplot(data, subplot_number, title):\n",
    "    print(\"plotting data with shape: %s\" %(len(data)))\n",
    "    print(title)\n",
    "    print(\"data: %s\" % data)\n",
    "    print(subplot_number)\n",
    "    plt.subplot(subplot_number)\n",
    "    # plt.pcolor(depths, range(seqs), np.abs(data), vmin=0., vmax=1.)\n",
    "    plt.pcolor(depths, range(seqs), np.abs(data))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(title)\n",
    "    if subplot_number > 244: ax.set_xlabel('Circuit depth')\n",
    "    ax.set_ylabel('Sequences')\n",
    "    ax.set_xticks(depths)\n",
    "    ax.set_yticks(np.arange(1, seqs + 1))\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "titles, data = [], []\n",
    "if not disjoint_counts:\n",
    "    for i in range(dim):\n",
    "        titles.append(f\"<{bin(i)[2:].zfill(n_qubits)}> Measured\")\n",
    "        titles.append(f\"<{bin(i)[2:].zfill(n_qubits)}> Expected\")\n",
    "        data.append(measured_probs[:, :, i])\n",
    "        data.append(expected_probs[:, :, i])\n",
    "else:\n",
    "    for i, q in enumerate(qubits):\n",
    "        for j in range(2):\n",
    "            titles.append(f\"q{q}<{j}> Measured\")\n",
    "            titles.append(f\"q{q}<{j}> Expected\")\n",
    "            data.append(measured_probs[i,:, :, j])\n",
    "            data.append(expected_probs[i, :, :, j])\n",
    "\n",
    "plot_number = [241, 242, 243, 244, 245, 246, 247, 248]\n",
    "\n",
    "k = 0\n",
    "for title, d, n in zip(titles, data, plot_number):\n",
    "    plt.suptitle(f\"XEB for q\"+ qubits_involved +f\", shots: {avgs}, sequences: {seqs}, max-depth/step: {max_depth}/{step}, CZ: {apply_cz}\")\n",
    "    create_subplot(d, n, title)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.7)\n",
    "    k+=1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google fXEB estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:44:52.014375Z",
     "start_time": "2024-03-22T03:44:52.004066Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if not disjoint_counts:\n",
    "    df = pd.DataFrame(records)\n",
    "    df[\"y\"] = df[\"m_u\"] - df[\"u_u\"]\n",
    "    df[\"x\"] = df[\"e_u\"] - df[\"u_u\"]\n",
    "    \n",
    "    df[\"numerator\"] = df[\"x\"] * df[\"y\"]\n",
    "    df[\"denominator\"] = df[\"x\"] ** 2\n",
    "    df.head()\n",
    "else:\n",
    "    df = [pd.DataFrame(record) for record in records]\n",
    "    for i in range(n_qubits):\n",
    "        df[i][\"y\"] = df[i][\"m_u\"] - df[i][\"u_u\"]\n",
    "        df[i][\"x\"] = df[i][\"e_u\"] - df[i][\"u_u\"]\n",
    "        \n",
    "        df[i][\"numerator\"] = df[i][\"x\"] * df[i][\"y\"]\n",
    "        df[i][\"denominator\"] = df[i][\"x\"] ** 2\n",
    "        df[i].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T03:52:28.422544Z",
     "start_time": "2024-03-22T03:52:27.829603Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = sns.cubehelix_palette(n_colors=len(depths))\n",
    "colors = {k: colors[i] for i, k in enumerate(depths)}\n",
    "_lines = []\n",
    "\n",
    "\n",
    "\n",
    "def per_cycle_depth(df):\n",
    "    fid_lsq = df[\"numerator\"].sum() / df[\"denominator\"].sum()\n",
    "\n",
    "    cycle_depth = df.name\n",
    "    xx = np.linspace(0, df[\"x\"].max())\n",
    "    (l,) = plt.plot(xx, fid_lsq * xx, color=colors[cycle_depth])\n",
    "    plt.scatter(df[\"x\"], df[\"y\"], color=colors[cycle_depth])\n",
    "\n",
    "    global _lines\n",
    "    _lines += [l]  # for legend\n",
    "    return pd.Series({\"fidelity\": fid_lsq})\n",
    "\n",
    "if not disjoint_counts:\n",
    "    fids = df.groupby(\"depth\").apply(per_cycle_depth).reset_index()\n",
    "    plt.xlabel(r\"$e_U - u_U$\", fontsize=18)\n",
    "    plt.ylabel(r\"$m_U - u_U$\", fontsize=18)\n",
    "    _lines = np.asarray(_lines)\n",
    "    plt.legend(_lines[[0, -1]], depths[[0, -1]], loc=\"best\", title=\"Cycle depth\")\n",
    "    plt.title(\"q-%s: Fxeb_linear = %s\" %(qubits, [fids[\"fidelity\"][x] for x in [0, 1]]))\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    fids = []\n",
    "    for i in range(n_qubits):\n",
    "        _lines = []\n",
    "        plt.figure()\n",
    "        fids.append(df[i].groupby(\"depth\").apply(per_cycle_depth).reset_index())\n",
    "        plt.xlabel(r\"$e_U - u_U$\", fontsize=18)\n",
    "        plt.ylabel(r\"$m_U - u_U$\", fontsize=18)\n",
    "        _lines = np.asarray(_lines)\n",
    "        plt.legend(_lines[[0, -1]], depths[[0, -1]], loc=\"best\", title=\"Cycle depth\")\n",
    "        plt.title(\"q-%s: Fxeb_linear = %s\" %(qubits[i], [fids[i][\"fidelity\"][x] for x in [0, 1]]))\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting fXEB curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T04:05:52.752418Z",
     "start_time": "2024-03-22T04:05:52.432285Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "\n",
    "plot_log_XEB = 1\n",
    "\n",
    "# Fit the data\n",
    "# def exponential_decay(cycle_depths: np.ndarray, a: float, layer_fid: float) -> np.ndarray:\n",
    "def exponential_decay(cycle_depths: np.ndarray, a: float, layer_fid: float, b: float) -> np.ndarray:\n",
    "    \"\"\"An exponential decay for fitting.\n",
    "\n",
    "    This computes `a * layer_fid**cycle_depths`\n",
    "\n",
    "    Args:\n",
    "        cycle_depths: The various depths at which fidelity was estimated. This is the independent\n",
    "            variable in the exponential function.\n",
    "        a: A scale parameter in the exponential function.\n",
    "        layer_fid: The base of the exponent in the exponential function.\n",
    "    \"\"\"\n",
    "    # return a * layer_fid**cycle_depths\n",
    "    return a * layer_fid**cycle_depths + b\n",
    "\n",
    "def _fit_exponential_decay(\n",
    "    cycle_depths: np.ndarray, fidelities: np.ndarray\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Fit an exponential model fidelity = a * layer_fid**x using nonlinear least squares.\n",
    "\n",
    "    This uses `exponential_decay` as the function to fit with parameters `a` and `layer_fid`.\n",
    "\n",
    "    Args:\n",
    "        cycle_depths: The various depths at which fidelity was estimated. Each element is `x`\n",
    "            in the fit expression.\n",
    "        fidelities: The estimated fidelities for each cycle depth. Each element is `fidelity`\n",
    "            in the fit expression.\n",
    "\n",
    "    Returns:\n",
    "        a: The first fit parameter that scales the exponential function, perhaps accounting for\n",
    "            state prep and measurement (SPAM) error.\n",
    "        layer_fid: The second fit parameters which serves as the base of the exponential.\n",
    "        a_std: The standard deviation of the `a` parameter estimate.\n",
    "        layer_fid_std: The standard deviation of the `layer_fid` parameter estimate.\n",
    "    \"\"\"\n",
    "    cycle_depths = np.asarray(cycle_depths)\n",
    "    fidelities = np.asarray(fidelities)\n",
    "    mask = (fidelities > 0) & (fidelities < 1)\n",
    "    masked_cycle_depths = cycle_depths[mask]\n",
    "    masked_fidelities = fidelities[mask]\n",
    "    \n",
    "    log_fidelities = np.log(masked_fidelities)\n",
    "\n",
    "    slope, intercept, _, _, _ = stats.linregress(masked_cycle_depths, log_fidelities)\n",
    "    layer_fid_0 = np.clip(np.exp(slope), 0, 1)\n",
    "    a_0 = np.clip(np.exp(intercept), 0, 1)\n",
    "    b_0 = 1\n",
    "\n",
    "    try:\n",
    "        # (a, layer_fid), pcov = optimize.curve_fit(\n",
    "        (a, layer_fid, b), pcov = optimize.curve_fit(\n",
    "            exponential_decay,\n",
    "            masked_cycle_depths,\n",
    "            masked_fidelities,\n",
    "            # p0=(a_0, layer_fid_0),\n",
    "            p0=(a_0, layer_fid_0, b_0),\n",
    "            # bounds=((0, 0), (1, 1)),\n",
    "            bounds=((0, 0, 0), (1, 1, 1)),\n",
    "            nan_policy='omit'\n",
    "        )\n",
    "    except ValueError:  # pragma: no cover\n",
    "        return 0, 0, np.inf, np.inf\n",
    "\n",
    "    # a_std, layer_fid_std = np.sqrt(np.diag(pcov))\n",
    "    a_std, layer_fid_std, b_std = np.sqrt(np.diag(pcov))\n",
    "    # return a, layer_fid, a_std, layer_fid_std\n",
    "    return a, layer_fid, a_std, layer_fid_std, b, b_std\n",
    "\n",
    "fit_google = True\n",
    "fit_log_entropy = True\n",
    "if not disjoint_counts:\n",
    "    xx = np.linspace(0, fids[\"depth\"].max())\n",
    "else:\n",
    "    xx = np.linspace(0, fids[0][\"depth\"].max())\n",
    "# In XEB, we extract the depolarizing fidelity, which is\n",
    "# related to (but not equal to) the Pauli error.\n",
    "# For the latter, an error involves doing X, Y, or Z with E_PAULI/3\n",
    "# but for the former, an error involves doing I, X, Y, or Z with e_depol/4\n",
    "try:\n",
    "    if not disjoint_counts:\n",
    "        # a, layer_fid, a_std, layer_fid_std = _fit_exponential_decay(fids[\"depth\"], fids[\"fidelity\"])\n",
    "        a, layer_fid, a_std, layer_fid_std, b, b_std = _fit_exponential_decay(fids[\"depth\"], fids[\"fidelity\"])\n",
    "        # plt.plot(xx, exponential_decay(xx, a, layer_fid),\n",
    "        plt.plot(xx, exponential_decay(xx, a, layer_fid, b),\n",
    "            label='Fit (Google processing), layer_fidelity={:.1f}%'.format(layer_fid*100),\n",
    "            color='red')\n",
    "        print(f\"a: {a}, b: {b}\")\n",
    "    else:\n",
    "        google_fit_params = []\n",
    "        for i in range(n_qubits):\n",
    "            a, layer_fid, a_std, layer_fid_std, b, b_std = _fit_exponential_decay(fids[i][\"depth\"], fids[i][\"fidelity\"])\n",
    "            plt.plot(xx, exponential_decay(xx, a, layer_fid, b),\n",
    "                label=f'Fit (Google processing) q{[qubits[i]]}, layer_fidelity={layer_fid*100:.1f}%',\n",
    "                color='red')\n",
    "            google_fit_params.append((a, layer_fid, a_std, layer_fid_std, b, b_std))\n",
    "            print(f\"qubit{qubits[i]}\", f\"a: {a}, b: {b}\")\n",
    "    \n",
    "except:\n",
    "    raise\n",
    "    print(\"Fit for Google processing data failed\")\n",
    "    fit_google = False\n",
    "\n",
    "try:\n",
    "    if not disjoint_counts:\n",
    "        Fxeb = np.nanmean(fidelities, axis=0)\n",
    "        # a2, layer_fid2, a_std2, layer_fid_std2 = _fit_exponential_decay(depths, Fxeb)\n",
    "        a2, layer_fid2, a_std2, layer_fid_std2, b2, b_std2 = _fit_exponential_decay(depths, Fxeb)\n",
    "        if plot_log_XEB:\n",
    "            # plt.plot(xx, exponential_decay(xx, a2, layer_fid2),\n",
    "            plt.plot(xx, exponential_decay(xx, a2, layer_fid2, b2),\n",
    "                label=\"Fit (Log-entropy processing), layer_fidelity={:.1f}%\".format(layer_fid2*100),\n",
    "                color=\"green\")\n",
    "    else:\n",
    "        Fxeb = np.nanmean(fidelities, axis=1)\n",
    "        log_fit_params = []\n",
    "        for i in range(n_qubits):\n",
    "            a2, layer_fid2, a_std2, layer_fid_std2, b2, b_std2 = _fit_exponential_decay(depths, Fxeb[i])\n",
    "            if plot_log_XEB:\n",
    "                plt.plot(xx, exponential_decay(xx, a2, layer_fid2, b2),\n",
    "                    label=f\"Fit (Log-entropy processing) q{[qubits[i]]}, layer_fidelity={layer_fid2*100:.1f}%\",\n",
    "                    color=\"green\")\n",
    "            log_fit_params.append((a2, layer_fid2, a_std2, layer_fid_std2, b2, b_std2))\n",
    "    \n",
    "except:\n",
    "    raise\n",
    "    print(\"Fit for Log-entropy processing data failed\")\n",
    "    fit_log_entropy = False\n",
    "\n",
    "if not disjoint_counts:\n",
    "    mask = (fids[\"fidelity\"] > 0) & (fids[\"fidelity\"] < 1)    \n",
    "    google_depths = fids[\"depth\"][mask]\n",
    "    google_fids =  fids[\"fidelity\"][mask]   \n",
    "    plt.plot(google_depths, google_fids, marker=\"o\", label=\"Google processing\")\n",
    "\n",
    "    mask_log = (Fxeb > 0) & (Fxeb < 1)\n",
    "\n",
    "    print(\"mask_log: %s\" %len(mask_log))\n",
    "    print(\"mask: %s\" %len(mask))\n",
    "    print(\"depths: %s\" %Fxeb)\n",
    "\n",
    "    if plot_log_XEB:\n",
    "        plt.scatter(depths[mask_log], Fxeb[mask_log], marker = 'o', color='green', label=\"Log-entropy processing\")\n",
    "else:\n",
    "    for i in range(n_qubits):\n",
    "        mask = (fids[i][\"fidelity\"] > 0) & (fids[i][\"fidelity\"] < 1)    \n",
    "        google_depths = fids[i][\"depth\"][mask]\n",
    "        google_fids =  fids[i][\"fidelity\"][mask]   \n",
    "        plt.plot(google_depths, google_fids, marker=\"o\", label=f\"Google processing q{qubits[i]}\")\n",
    "        \n",
    "        mask_log = (Fxeb[i] > 0) & (Fxeb[i] < 1)\n",
    "        \n",
    "        print(\"mask_log: %s\" %len(mask_log))\n",
    "        print(\"mask: %s\" %len(mask))\n",
    "        print(\"depths: %s\" %Fxeb[i])\n",
    "        \n",
    "        if plot_log_XEB:\n",
    "            plt.scatter(depths[mask_log], Fxeb[i][mask_log], marker = 'o', color='green', label=f\"Log-entropy processing q{qubits[i]}\")\n",
    "\n",
    "plt.ylabel(\"Circuit fidelity\", fontsize=20)\n",
    "plt.xlabel(\"Cycle Depth $d$\", fontsize=20)\n",
    "plt.title(\"XEB Fidelity\")\n",
    "plt.legend(loc=\"best\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T04:05:27.355587Z",
     "start_time": "2024-03-22T04:05:27.348833Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not disjoint_counts:\n",
    "    if fit_google:\n",
    "        print(\"Google processing fit:\")\n",
    "        print(\"Params: \", a, layer_fid)\n",
    "        print(\"layer-fidelity: \", layer_fid)\n",
    "    if fit_log_entropy:\n",
    "        print(\"Log-entropy processing fit:\")\n",
    "        print(\"Params: \", a2, layer_fid2)\n",
    "        print(\"layer-fidelity: \", layer_fid2)\n",
    "else:\n",
    "    for i in range(n_qubits):\n",
    "        if fit_google:\n",
    "            print(f\"Google processing fit q{qubits[i]}:\")\n",
    "            print(\"Params: \",google_fit_params[i][0], google_fit_params[i][1])\n",
    "            print(\"layer-fidelity: \", google_fit_params[i][1])\n",
    "        if fit_log_entropy:\n",
    "            print(f\"Log-entropy processing fit q{qubits[i]}:\")\n",
    "            print(\"Params: \", log_fit_params[i][0], log_fit_params[i][1])\n",
    "            print(\"layer-fidelity: \", log_fit_params[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not disjoint_counts:\n",
    "    print(f\"Currently used in the QM XEB example:\\n {Fxeb}\") # Derived from the fSim paper\n",
    "    print(f'Linear XEB of Google:\\n {fids[\"fidelity\"]}') # from Google's Supremacy paper\n",
    "else:\n",
    "    for i in range(n_qubits):\n",
    "        print(f\"Currently used in the QM XEB example:\\n {Fxeb[i]}\") # Derived from the fSim paper\n",
    "        print(f'Linear XEB of Google:\\n {fids[i][\"fidelity\"]}') # from Google's Supremacy paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not disjoint_counts:\n",
    "    print(\"relative difference\", np.abs(fids[\"fidelity\"] - Fxeb))\n",
    "else:\n",
    "    for i in range(n_qubits):\n",
    "        print(f\"relative difference {q[qubits[i]]}\", np.abs(fids[i][\"fidelity\"] - Fxeb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not disjoint_counts:\n",
    "    plt.figure()\n",
    "    plt.title(\"Relative difference between Google and derived XEB fidelities\")\n",
    "    plt.plot(depths, (fids[\"fidelity\"]-Fxeb)/Fxeb, 'o', label=\"XEB fidelity\")\n",
    "else:\n",
    "    for i in range(n_qubits):\n",
    "        plt.figure()\n",
    "        plt.title(f\"Relative difference between Google and derived XEB fidelities {q[qubits[i]]}\")\n",
    "        plt.plot(depths, (fids[i][\"fidelity\"]-Fxeb[i])/Fxeb[i], 'o', label=\"XEB fidelity\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QPX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
